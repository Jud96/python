{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-05T20:15:51.258790Z","iopub.execute_input":"2022-01-05T20:15:51.259125Z","iopub.status.idle":"2022-01-05T20:15:51.275604Z","shell.execute_reply.started":"2022-01-05T20:15:51.259088Z","shell.execute_reply":"2022-01-05T20:15:51.274885Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/input/smileannotaions/smile-annotations-final.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Task 1: Introduction\nWhat is BERT\nBERT is a large-scale transformer-based Language Model that can be finetuned for a variety of tasks.\n\n## Task 2: Exploratory Data Analysis and Preprocessing\nWe will use the SMILE Twitter dataset.\n","metadata":{}},{"cell_type":"code","source":"import torch\nimport pandas as pd\nfrom tqdm.notebook import tqdm","metadata":{"execution":{"iopub.status.busy":"2022-01-05T20:15:51.277305Z","iopub.execute_input":"2022-01-05T20:15:51.277565Z","iopub.status.idle":"2022-01-05T20:15:52.883472Z","shell.execute_reply.started":"2022-01-05T20:15:51.277528Z","shell.execute_reply":"2022-01-05T20:15:52.882686Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/smileannotaions/smile-annotations-final.csv\", names = ['id','text','category'])","metadata":{"execution":{"iopub.status.busy":"2022-01-05T20:15:52.885558Z","iopub.execute_input":"2022-01-05T20:15:52.886070Z","iopub.status.idle":"2022-01-05T20:15:52.919451Z","shell.execute_reply.started":"2022-01-05T20:15:52.886033Z","shell.execute_reply":"2022-01-05T20:15:52.918717Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df.set_index('id',inplace = True)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T20:15:52.922411Z","iopub.execute_input":"2022-01-05T20:15:52.922638Z","iopub.status.idle":"2022-01-05T20:15:52.935182Z","shell.execute_reply.started":"2022-01-05T20:15:52.922610Z","shell.execute_reply":"2022-01-05T20:15:52.934458Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df.head()\ndf.text.iloc[0]","metadata":{"execution":{"iopub.status.busy":"2022-01-05T20:15:52.937359Z","iopub.execute_input":"2022-01-05T20:15:52.938127Z","iopub.status.idle":"2022-01-05T20:15:52.948137Z","shell.execute_reply.started":"2022-01-05T20:15:52.938090Z","shell.execute_reply":"2022-01-05T20:15:52.947411Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"'@aandraous @britishmuseum @AndrewsAntonio Merci pour le partage! @openwinemap'"},"metadata":{}}]},{"cell_type":"code","source":"df.category.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-01-05T20:15:52.949615Z","iopub.execute_input":"2022-01-05T20:15:52.950315Z","iopub.status.idle":"2022-01-05T20:15:52.960255Z","shell.execute_reply.started":"2022-01-05T20:15:52.950278Z","shell.execute_reply":"2022-01-05T20:15:52.959560Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"nocode               1572\nhappy                1137\nnot-relevant          214\nangry                  57\nsurprise               35\nsad                    32\nhappy|surprise         11\nhappy|sad               9\ndisgust|angry           7\ndisgust                 6\nsad|disgust             2\nsad|angry               2\nsad|disgust|angry       1\nName: category, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"df = df[-df.category.str.contains(\"\\|\")]\ndf = df[df.category != 'nocode']","metadata":{"execution":{"iopub.status.busy":"2022-01-05T20:15:52.961462Z","iopub.execute_input":"2022-01-05T20:15:52.962028Z","iopub.status.idle":"2022-01-05T20:15:52.972260Z","shell.execute_reply.started":"2022-01-05T20:15:52.961983Z","shell.execute_reply":"2022-01-05T20:15:52.971578Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"df.category.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-01-05T20:15:52.973569Z","iopub.execute_input":"2022-01-05T20:15:52.973813Z","iopub.status.idle":"2022-01-05T20:15:52.981999Z","shell.execute_reply.started":"2022-01-05T20:15:52.973780Z","shell.execute_reply":"2022-01-05T20:15:52.981089Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"happy           1137\nnot-relevant     214\nangry             57\nsurprise          35\nsad               32\ndisgust            6\nName: category, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"possible_labels = df.category.unique()\npossible_labels","metadata":{"execution":{"iopub.status.busy":"2022-01-05T20:15:52.983350Z","iopub.execute_input":"2022-01-05T20:15:52.983994Z","iopub.status.idle":"2022-01-05T20:15:52.990319Z","shell.execute_reply.started":"2022-01-05T20:15:52.983955Z","shell.execute_reply":"2022-01-05T20:15:52.989411Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"array(['happy', 'not-relevant', 'angry', 'disgust', 'sad', 'surprise'],\n      dtype=object)"},"metadata":{}}]},{"cell_type":"code","source":"label_dict = {}\nfor index,possible_label in enumerate(possible_labels):\n    label_dict[possible_label] = index","metadata":{"execution":{"iopub.status.busy":"2022-01-05T20:15:52.991332Z","iopub.execute_input":"2022-01-05T20:15:52.992985Z","iopub.status.idle":"2022-01-05T20:15:52.998919Z","shell.execute_reply.started":"2022-01-05T20:15:52.992948Z","shell.execute_reply":"2022-01-05T20:15:52.997980Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"df['label'] = df.category.replace(label_dict)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T20:15:53.001115Z","iopub.execute_input":"2022-01-05T20:15:53.001845Z","iopub.status.idle":"2022-01-05T20:15:53.013477Z","shell.execute_reply.started":"2022-01-05T20:15:53.001799Z","shell.execute_reply":"2022-01-05T20:15:53.012577Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-05T20:15:53.014565Z","iopub.execute_input":"2022-01-05T20:15:53.015407Z","iopub.status.idle":"2022-01-05T20:15:53.032455Z","shell.execute_reply.started":"2022-01-05T20:15:53.015354Z","shell.execute_reply":"2022-01-05T20:15:53.031784Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"                                                                 text  \\\nid                                                                      \n614484565059596288  Dorian Gray with Rainbow Scarf #LoveWins (from...   \n614746522043973632  @SelectShowcase @Tate_StIves ... Replace with ...   \n614877582664835073  @Sofabsports thank you for following me back. ...   \n611932373039644672  @britishmuseum @TudorHistory What a beautiful ...   \n611570404268883969  @NationalGallery @ThePoldarkian I have always ...   \n\n                   category  label  \nid                                  \n614484565059596288    happy      0  \n614746522043973632    happy      0  \n614877582664835073    happy      0  \n611932373039644672    happy      0  \n611570404268883969    happy      0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>category</th>\n      <th>label</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>614484565059596288</th>\n      <td>Dorian Gray with Rainbow Scarf #LoveWins (from...</td>\n      <td>happy</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>614746522043973632</th>\n      <td>@SelectShowcase @Tate_StIves ... Replace with ...</td>\n      <td>happy</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>614877582664835073</th>\n      <td>@Sofabsports thank you for following me back. ...</td>\n      <td>happy</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>611932373039644672</th>\n      <td>@britishmuseum @TudorHistory What a beautiful ...</td>\n      <td>happy</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>611570404268883969</th>\n      <td>@NationalGallery @ThePoldarkian I have always ...</td>\n      <td>happy</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Task 3: Training/Validation Split","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2022-01-05T20:15:53.033855Z","iopub.execute_input":"2022-01-05T20:15:53.034350Z","iopub.status.idle":"2022-01-05T20:15:53.936126Z","shell.execute_reply.started":"2022-01-05T20:15:53.034312Z","shell.execute_reply":"2022-01-05T20:15:53.935054Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"x_train,x_val,y_train,y_val = train_test_split(\n    df.index.values , df.label.values , test_size= 0.15 , random_state= 17 , stratify= df.label.values)\ndf['data_type'] = ['not_set'] * df.shape[0]\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-05T20:15:53.940936Z","iopub.execute_input":"2022-01-05T20:15:53.941451Z","iopub.status.idle":"2022-01-05T20:15:53.967679Z","shell.execute_reply.started":"2022-01-05T20:15:53.941415Z","shell.execute_reply":"2022-01-05T20:15:53.967046Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"                                                                 text  \\\nid                                                                      \n614484565059596288  Dorian Gray with Rainbow Scarf #LoveWins (from...   \n614746522043973632  @SelectShowcase @Tate_StIves ... Replace with ...   \n614877582664835073  @Sofabsports thank you for following me back. ...   \n611932373039644672  @britishmuseum @TudorHistory What a beautiful ...   \n611570404268883969  @NationalGallery @ThePoldarkian I have always ...   \n\n                   category  label data_type  \nid                                            \n614484565059596288    happy      0   not_set  \n614746522043973632    happy      0   not_set  \n614877582664835073    happy      0   not_set  \n611932373039644672    happy      0   not_set  \n611570404268883969    happy      0   not_set  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>category</th>\n      <th>label</th>\n      <th>data_type</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>614484565059596288</th>\n      <td>Dorian Gray with Rainbow Scarf #LoveWins (from...</td>\n      <td>happy</td>\n      <td>0</td>\n      <td>not_set</td>\n    </tr>\n    <tr>\n      <th>614746522043973632</th>\n      <td>@SelectShowcase @Tate_StIves ... Replace with ...</td>\n      <td>happy</td>\n      <td>0</td>\n      <td>not_set</td>\n    </tr>\n    <tr>\n      <th>614877582664835073</th>\n      <td>@Sofabsports thank you for following me back. ...</td>\n      <td>happy</td>\n      <td>0</td>\n      <td>not_set</td>\n    </tr>\n    <tr>\n      <th>611932373039644672</th>\n      <td>@britishmuseum @TudorHistory What a beautiful ...</td>\n      <td>happy</td>\n      <td>0</td>\n      <td>not_set</td>\n    </tr>\n    <tr>\n      <th>611570404268883969</th>\n      <td>@NationalGallery @ThePoldarkian I have always ...</td>\n      <td>happy</td>\n      <td>0</td>\n      <td>not_set</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.loc[x_train ,'data_type'] = 'train'\ndf.loc[x_val ,'data_type'] = 'val'","metadata":{"execution":{"iopub.status.busy":"2022-01-05T20:15:53.969824Z","iopub.execute_input":"2022-01-05T20:15:53.970346Z","iopub.status.idle":"2022-01-05T20:15:53.979283Z","shell.execute_reply.started":"2022-01-05T20:15:53.970308Z","shell.execute_reply":"2022-01-05T20:15:53.978717Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"df.groupby(['category' ,'label','data_type'] ).count()","metadata":{"execution":{"iopub.status.busy":"2022-01-05T20:15:53.980525Z","iopub.execute_input":"2022-01-05T20:15:53.981084Z","iopub.status.idle":"2022-01-05T20:15:54.007407Z","shell.execute_reply.started":"2022-01-05T20:15:53.981044Z","shell.execute_reply":"2022-01-05T20:15:54.006390Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"                              text\ncategory     label data_type      \nangry        2     train        48\n                   val           9\ndisgust      3     train         5\n                   val           1\nhappy        0     train       966\n                   val         171\nnot-relevant 1     train       182\n                   val          32\nsad          4     train        27\n                   val           5\nsurprise     5     train        30\n                   val           5","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>text</th>\n    </tr>\n    <tr>\n      <th>category</th>\n      <th>label</th>\n      <th>data_type</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">angry</th>\n      <th rowspan=\"2\" valign=\"top\">2</th>\n      <th>train</th>\n      <td>48</td>\n    </tr>\n    <tr>\n      <th>val</th>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">disgust</th>\n      <th rowspan=\"2\" valign=\"top\">3</th>\n      <th>train</th>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>val</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">happy</th>\n      <th rowspan=\"2\" valign=\"top\">0</th>\n      <th>train</th>\n      <td>966</td>\n    </tr>\n    <tr>\n      <th>val</th>\n      <td>171</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">not-relevant</th>\n      <th rowspan=\"2\" valign=\"top\">1</th>\n      <th>train</th>\n      <td>182</td>\n    </tr>\n    <tr>\n      <th>val</th>\n      <td>32</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">sad</th>\n      <th rowspan=\"2\" valign=\"top\">4</th>\n      <th>train</th>\n      <td>27</td>\n    </tr>\n    <tr>\n      <th>val</th>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">surprise</th>\n      <th rowspan=\"2\" valign=\"top\">5</th>\n      <th>train</th>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>val</th>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Task 4: Loading Tokenizer and Encoding our Data","metadata":{}},{"cell_type":"code","source":"from transformers import BertTokenizer\nfrom torch.utils.data import TensorDataset","metadata":{"execution":{"iopub.status.busy":"2022-01-05T20:15:54.008745Z","iopub.execute_input":"2022-01-05T20:15:54.009079Z","iopub.status.idle":"2022-01-05T20:15:59.134417Z","shell.execute_reply.started":"2022-01-05T20:15:54.009041Z","shell.execute_reply":"2022-01-05T20:15:59.133535Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained('bert-base-uncased' , do_lower_case = True)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T20:15:59.135740Z","iopub.execute_input":"2022-01-05T20:15:59.136034Z","iopub.status.idle":"2022-01-05T20:16:01.440341Z","shell.execute_reply.started":"2022-01-05T20:15:59.135998Z","shell.execute_reply":"2022-01-05T20:16:01.439659Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"358a525e69c343f9b068cb6a532643c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f0110b84d1f4f6da51a9af1337410e8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a7fb02b2f4674d56a4fd58c9ed5635f8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9a19d17d9c940c4bedfd07705400118"}},"metadata":{}}]},{"cell_type":"code","source":"encoded_data_train =  tokenizer.batch_encode_plus(\n            df[df.data_type == 'train'].text.values , \n            add_special_tokens=True , \n            return_attention_mask=True,\n            pad_to_max_length = True,\n            max_length=250 ,\n            return_tensors='pt')\n\nencoded_data_val =  tokenizer.batch_encode_plus(\n            df[df.data_type == 'val'].text.values , \n            add_special_tokens=True , \n            return_attention_mask=True,\n            pad_to_max_length = True,\n            max_length=250 ,\n            return_tensors='pt')\n\n\ninputs_ids_train = encoded_data_train['input_ids']\nattention_mask_train = encoded_data_train['attention_mask']\nlabels_train = torch.tensor(df[df.data_type == 'train'].label.values)\n\ninputs_ids_val = encoded_data_val['input_ids']\nattention_mask_val = encoded_data_val['attention_mask']\nlabels_val = torch.tensor(df[df.data_type == 'val'].label.values)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T20:16:01.441705Z","iopub.execute_input":"2022-01-05T20:16:01.441983Z","iopub.status.idle":"2022-01-05T20:16:02.760200Z","shell.execute_reply.started":"2022-01-05T20:16:01.441948Z","shell.execute_reply":"2022-01-05T20:16:02.759384Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  FutureWarning,\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset_train = TensorDataset(inputs_ids_train , attention_mask_train , labels_train)\ndataset_val   = TensorDataset(inputs_ids_val , attention_mask_val , labels_val)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T20:16:02.761505Z","iopub.execute_input":"2022-01-05T20:16:02.761779Z","iopub.status.idle":"2022-01-05T20:16:02.767686Z","shell.execute_reply.started":"2022-01-05T20:16:02.761744Z","shell.execute_reply":"2022-01-05T20:16:02.766834Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"len(dataset_train)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T20:16:02.769021Z","iopub.execute_input":"2022-01-05T20:16:02.769369Z","iopub.status.idle":"2022-01-05T20:16:02.779172Z","shell.execute_reply.started":"2022-01-05T20:16:02.769314Z","shell.execute_reply":"2022-01-05T20:16:02.777753Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"1258"},"metadata":{}}]},{"cell_type":"code","source":"len(dataset_val)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T20:16:02.780751Z","iopub.execute_input":"2022-01-05T20:16:02.781674Z","iopub.status.idle":"2022-01-05T20:16:02.787461Z","shell.execute_reply.started":"2022-01-05T20:16:02.781633Z","shell.execute_reply":"2022-01-05T20:16:02.786640Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"223"},"metadata":{}}]},{"cell_type":"markdown","source":"## Task 5: Setting up BERT Pretrained Model","metadata":{}},{"cell_type":"code","source":"from transformers import BertForSequenceClassification","metadata":{"execution":{"iopub.status.busy":"2022-01-05T20:16:02.789236Z","iopub.execute_input":"2022-01-05T20:16:02.789714Z","iopub.status.idle":"2022-01-05T20:16:02.811515Z","shell.execute_reply.started":"2022-01-05T20:16:02.789671Z","shell.execute_reply":"2022-01-05T20:16:02.810766Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"model = BertForSequenceClassification.from_pretrained(\n        'bert-base-uncased',\n        num_labels= len(label_dict),\n        output_attentions = False ,\n        output_hidden_states = False)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T20:16:02.812735Z","iopub.execute_input":"2022-01-05T20:16:02.813406Z","iopub.status.idle":"2022-01-05T20:16:20.053526Z","shell.execute_reply.started":"2022-01-05T20:16:02.813360Z","shell.execute_reply":"2022-01-05T20:16:20.052865Z"},"trusted":true},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b4d5ff1e42b46d5bffb5f9eea31bd54"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Task 6: Creating Data Loaders","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import DataLoader, RandomSampler, SequentialSampler","metadata":{"execution":{"iopub.status.busy":"2022-01-05T20:16:20.055043Z","iopub.execute_input":"2022-01-05T20:16:20.055321Z","iopub.status.idle":"2022-01-05T20:16:20.061682Z","shell.execute_reply.started":"2022-01-05T20:16:20.055286Z","shell.execute_reply":"2022-01-05T20:16:20.059540Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"dataloader_train = DataLoader(dataset_train ,\n                              sampler= RandomSampler(dataset_train),\n                             batch_size = 4)\n\ndataloader_val = DataLoader(dataset_val ,\n                              sampler= RandomSampler(dataset_val),\n                             batch_size = 32)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T20:16:20.063514Z","iopub.execute_input":"2022-01-05T20:16:20.064154Z","iopub.status.idle":"2022-01-05T20:16:20.277492Z","shell.execute_reply.started":"2022-01-05T20:16:20.064018Z","shell.execute_reply":"2022-01-05T20:16:20.276683Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"## Task 7: Setting Up Optimizer and Scheduler","metadata":{}},{"cell_type":"code","source":"from transformers import AdamW, get_linear_schedule_with_warmup","metadata":{"execution":{"iopub.status.busy":"2022-01-05T20:16:20.279791Z","iopub.execute_input":"2022-01-05T20:16:20.280364Z","iopub.status.idle":"2022-01-05T20:16:20.291427Z","shell.execute_reply.started":"2022-01-05T20:16:20.280307Z","shell.execute_reply":"2022-01-05T20:16:20.290641Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"optimizer = AdamW(model.parameters() ,lr = 1e-5 , eps = 1e-8)\nepochs = 10","metadata":{"execution":{"iopub.status.busy":"2022-01-05T20:16:20.292996Z","iopub.execute_input":"2022-01-05T20:16:20.295760Z","iopub.status.idle":"2022-01-05T20:16:20.303517Z","shell.execute_reply.started":"2022-01-05T20:16:20.295732Z","shell.execute_reply":"2022-01-05T20:16:20.302726Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"scheduler = get_linear_schedule_with_warmup(optimizer ,\n                                            num_warmup_steps= 0,\n                                           num_training_steps= len(dataloader_train)*epochs)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T20:16:20.304913Z","iopub.execute_input":"2022-01-05T20:16:20.305255Z","iopub.status.idle":"2022-01-05T20:16:20.310164Z","shell.execute_reply.started":"2022-01-05T20:16:20.305220Z","shell.execute_reply":"2022-01-05T20:16:20.309398Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"## Task 8: Defining our Performance Metrics","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import f1_score","metadata":{"execution":{"iopub.status.busy":"2022-01-05T20:16:20.311816Z","iopub.execute_input":"2022-01-05T20:16:20.312605Z","iopub.status.idle":"2022-01-05T20:16:20.318234Z","shell.execute_reply.started":"2022-01-05T20:16:20.312571Z","shell.execute_reply":"2022-01-05T20:16:20.317522Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"def f1_score_func(preds, labels):\n    preds_flat = np.argmax(preds , axis =1).flatten()\n    labels_flat = labels.flatten()\n    return f1_score(labels_flat , preds_flat , average=\"weighted\")","metadata":{"execution":{"iopub.status.busy":"2022-01-05T20:16:20.319548Z","iopub.execute_input":"2022-01-05T20:16:20.320291Z","iopub.status.idle":"2022-01-05T20:16:20.325440Z","shell.execute_reply.started":"2022-01-05T20:16:20.320257Z","shell.execute_reply":"2022-01-05T20:16:20.324667Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"def accuracy_per_class(preds, labels):\n    labels_dict_inverse = {v:k for k,v in label_dict.items()}\n    \n    preds_flat = np.argmax(preds , axis =1).flatten()\n    labels_flat = labels.flatten()\n    \n    for label in np.unique(labels_flat):\n        y_preds = preds_flat[labels_flat == label]\n        y_true  = labels_flat[labels_flat == label]\n        print(f'class:{labels_dict_inverse[label]}')\n        print(f'accuracy:{len(y_preds[y_preds == label])}/{len(y_true)}\\n')","metadata":{"execution":{"iopub.status.busy":"2022-01-05T20:44:41.161446Z","iopub.execute_input":"2022-01-05T20:44:41.161703Z","iopub.status.idle":"2022-01-05T20:44:41.167080Z","shell.execute_reply.started":"2022-01-05T20:44:41.161674Z","shell.execute_reply":"2022-01-05T20:44:41.166399Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"markdown","source":"## Task 9: Creating our Training Loop","metadata":{}},{"cell_type":"code","source":"import random\n\nseed_val = 17\nrandom.seed(seed_val)\nnp.random.seed(seed_val)\ntorch.manual_seed(seed_val)\ntorch.cuda.manual_seed_all(seed_val)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T20:16:20.335893Z","iopub.execute_input":"2022-01-05T20:16:20.336344Z","iopub.status.idle":"2022-01-05T20:16:20.345227Z","shell.execute_reply.started":"2022-01-05T20:16:20.336308Z","shell.execute_reply":"2022-01-05T20:16:20.344538Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T20:16:20.346492Z","iopub.execute_input":"2022-01-05T20:16:20.346748Z","iopub.status.idle":"2022-01-05T20:16:24.865984Z","shell.execute_reply.started":"2022-01-05T20:16:20.346716Z","shell.execute_reply":"2022-01-05T20:16:24.864966Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"def evaluate(dataloader_val):\n\n    model.eval()\n    \n    loss_val_total = 0\n    predictions, true_vals = [], []\n    \n    for batch in tqdm(dataloader_val):\n        \n        batch = tuple(b.to(device) for b in batch)\n        \n        inputs = {'input_ids':      batch[0],\n                  'attention_mask': batch[1],\n                  'labels':         batch[2]\n                 }\n\n        with torch.no_grad():        \n            outputs = model(**inputs)\n            \n        loss = outputs[0]\n        logits = outputs[1]\n        loss_val_total += loss.item()\n\n        logits = logits.detach().cpu().numpy()\n        label_ids = inputs['labels'].cpu().numpy()\n        predictions.append(logits)\n        true_vals.append(label_ids)\n    \n    loss_val_avg = loss_val_total/len(dataloader_val)  \n    predictions = np.concatenate(predictions, axis=0)\n    true_vals = np.concatenate(true_vals, axis=0)\n            \n    return loss_val_avg, predictions, true_vals","metadata":{"execution":{"iopub.status.busy":"2022-01-05T20:16:24.867598Z","iopub.execute_input":"2022-01-05T20:16:24.868107Z","iopub.status.idle":"2022-01-05T20:16:24.879430Z","shell.execute_reply.started":"2022-01-05T20:16:24.868067Z","shell.execute_reply":"2022-01-05T20:16:24.878519Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"for epoch in tqdm(range(1, epochs+1)):\n    model.train()\n    loss_train_total = 0\n    progress_bar = tqdm(dataloader_train , \n                        desc = 'epoch {:I=1d}'.format(epoch),\n                       leave = False , \n                       disable = False)\n    for batch in progress_bar:\n        model.zero_grad()\n        batch = tuple(b.to(device) for b in batch)\n        inputs ={'input_ids' : batch[0],\n                 'attention_mask':batch[1],\n                 'labels' : batch[2]}\n        outputs = model(**inputs)\n        loss = outputs[0]\n        loss_train_total += loss.item()\n        loss.backward()\n        \n        torch.nn.utils.clip_grad_norm_(model.parameters(),1)\n        optimizer.step()\n        scheduler.step()\n        progress_bar.set_postfix({'training_loss':'{:3f}'.format(loss.item()/len(batch))})\n   # torch.save(model.state_dict(),f'Models/Bert_ft_epoch{epoch}.model')\n    tqdm.write('\\nEpoch{epoch}')\n    loss_train_avg = loss_train_total/len(dataloader_train)\n        \n    tqdm.write(f'training_loss :{loss_train_avg}')\n    val_loss , predictions ,true_values = evaluate(dataloader_val)\n    val_f1 = f1_score_func(predictions , true_values)\n    tqdm.write(f'validation loss :{val_loss}')\n    tqdm.write(f'F1_score(weighted) :{val_f1}')","metadata":{"execution":{"iopub.status.busy":"2022-01-05T20:16:24.882509Z","iopub.execute_input":"2022-01-05T20:16:24.885060Z","iopub.status.idle":"2022-01-05T20:23:53.825680Z","shell.execute_reply.started":"2022-01-05T20:16:24.885018Z","shell.execute_reply":"2022-01-05T20:23:53.824987Z"},"trusted":true},"execution_count":38,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"689198f6d2e64c1683261d75b1400e3f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"epoch 1:   0%|          | 0/315 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\nEpoch{epoch}\ntraining_loss :0.7689728549548558\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00a0ea5884064cbe82c616966a89f876"}},"metadata":{}},{"name":"stdout","text":"validation loss :0.5855848448617118\nF1_score(weighted) :0.7769166003988482\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"epoch 2:   0%|          | 0/315 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\nEpoch{epoch}\ntraining_loss :0.4481437216231984\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a26760cafdb4480582977f7aca908069"}},"metadata":{}},{"name":"stdout","text":"validation loss :0.6229808756283352\nF1_score(weighted) :0.8484651828119184\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"epoch 3:   0%|          | 0/315 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\nEpoch{epoch}\ntraining_loss :0.2783280083296141\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec8d6849b0f34dd7b49851d08b3c5e22"}},"metadata":{}},{"name":"stdout","text":"validation loss :0.6635871529579163\nF1_score(weighted) :0.8401985906470213\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"epoch 4:   0%|          | 0/315 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\nEpoch{epoch}\ntraining_loss :0.1899415168811434\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad913a3b96ad493a8e0911469afb97a1"}},"metadata":{}},{"name":"stdout","text":"validation loss :0.6129864241395678\nF1_score(weighted) :0.8546580244026889\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"epoch 5:   0%|          | 0/315 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\nEpoch{epoch}\ntraining_loss :0.12844385036511258\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e4ee337b24d48a5bbc1ae5e6efd7d7c"}},"metadata":{}},{"name":"stdout","text":"validation loss :0.7755047785384315\nF1_score(weighted) :0.8394140153643124\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"epoch 6:   0%|          | 0/315 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\nEpoch{epoch}\ntraining_loss :0.06722971337925022\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b89b1e182729416d8bb9b2fb086c0b52"}},"metadata":{}},{"name":"stdout","text":"validation loss :0.7495512962341309\nF1_score(weighted) :0.8534744513378119\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"epoch 7:   0%|          | 0/315 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\nEpoch{epoch}\ntraining_loss :0.0484527624299055\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb20e31566c9407a9697c45dcb178d1f"}},"metadata":{}},{"name":"stdout","text":"validation loss :0.7906738945416042\nF1_score(weighted) :0.8562845973159876\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"epoch 8:   0%|          | 0/315 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\nEpoch{epoch}\ntraining_loss :0.031391148478169706\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c9afe96bd2543029ba723b999a121c3"}},"metadata":{}},{"name":"stdout","text":"validation loss :0.8315566395010267\nF1_score(weighted) :0.8547498447681376\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"epoch 9:   0%|          | 0/315 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\nEpoch{epoch}\ntraining_loss :0.023054983788391666\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03424ef937cc49d5982c4e358289bdf9"}},"metadata":{}},{"name":"stdout","text":"validation loss :0.7830214330128261\nF1_score(weighted) :0.8599325729086263\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"epoch 10:   0%|          | 0/315 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\nEpoch{epoch}\ntraining_loss :0.022075138912011412\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0daaee0b1614cfeaabba903d83356cf"}},"metadata":{}},{"name":"stdout","text":"validation loss :0.8066349284989494\nF1_score(weighted) :0.8708976807159483\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## save model ","metadata":{}},{"cell_type":"code","source":"torch.save(model.state_dict(),'../working/sentiment_Analysis.model')","metadata":{"execution":{"iopub.status.busy":"2022-01-05T20:23:53.827177Z","iopub.execute_input":"2022-01-05T20:23:53.827655Z","iopub.status.idle":"2022-01-05T20:23:54.551601Z","shell.execute_reply.started":"2022-01-05T20:23:53.827618Z","shell.execute_reply":"2022-01-05T20:23:54.550901Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"## Task 10: Loading and Evaluating our Model\n","metadata":{}},{"cell_type":"code","source":"from transformers import BertForSequenceClassification","metadata":{"execution":{"iopub.status.busy":"2022-01-05T20:23:54.552758Z","iopub.execute_input":"2022-01-05T20:23:54.553046Z","iopub.status.idle":"2022-01-05T20:23:54.557681Z","shell.execute_reply.started":"2022-01-05T20:23:54.553010Z","shell.execute_reply":"2022-01-05T20:23:54.557060Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"model2 = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n                                                      num_labels=6,\n                                                      output_attentions=False,\n                                                      output_hidden_states=False\n                                                      )","metadata":{"execution":{"iopub.status.busy":"2022-01-05T20:23:54.558911Z","iopub.execute_input":"2022-01-05T20:23:54.559384Z","iopub.status.idle":"2022-01-05T20:23:56.344280Z","shell.execute_reply.started":"2022-01-05T20:23:54.559320Z","shell.execute_reply":"2022-01-05T20:23:56.343625Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel2.to(device)\nprint(device)\npass","metadata":{"execution":{"iopub.status.busy":"2022-01-05T20:23:56.345406Z","iopub.execute_input":"2022-01-05T20:23:56.345848Z","iopub.status.idle":"2022-01-05T20:23:56.465258Z","shell.execute_reply.started":"2022-01-05T20:23:56.345768Z","shell.execute_reply":"2022-01-05T20:23:56.464536Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"model2.load_state_dict(torch.load('../working/sentiment_Analysis.model' ,map_location=torch.device('cuda') ) )","metadata":{"execution":{"iopub.status.busy":"2022-01-05T20:35:42.535550Z","iopub.execute_input":"2022-01-05T20:35:42.535803Z","iopub.status.idle":"2022-01-05T20:35:42.764652Z","shell.execute_reply.started":"2022-01-05T20:35:42.535776Z","shell.execute_reply":"2022-01-05T20:35:42.763871Z"},"trusted":true},"execution_count":56,"outputs":[{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"_,predictions,true_vals = evaluate(dataloader_val)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T20:38:51.864578Z","iopub.execute_input":"2022-01-05T20:38:51.865279Z","iopub.status.idle":"2022-01-05T20:38:53.693420Z","shell.execute_reply.started":"2022-01-05T20:38:51.865236Z","shell.execute_reply":"2022-01-05T20:38:53.692592Z"},"trusted":true},"execution_count":61,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4fa84c2fdd6c4367a130826751d5a5b7"}},"metadata":{}}]},{"cell_type":"code","source":"predictions","metadata":{"execution":{"iopub.status.busy":"2022-01-05T20:38:56.243323Z","iopub.execute_input":"2022-01-05T20:38:56.243789Z","iopub.status.idle":"2022-01-05T20:38:56.249354Z","shell.execute_reply.started":"2022-01-05T20:38:56.243752Z","shell.execute_reply":"2022-01-05T20:38:56.248513Z"},"trusted":true},"execution_count":62,"outputs":[{"execution_count":62,"output_type":"execute_result","data":{"text/plain":"array([[ 7.7751017 , -1.2679998 , -2.2954752 , -1.8883604 , -1.2804353 ,\n        -1.9283006 ],\n       [ 7.789495  , -1.6507716 , -2.2226288 , -1.7088171 , -1.2414494 ,\n        -1.7250088 ],\n       [ 7.79996   , -1.218955  , -2.5107586 , -1.8783234 , -1.1751504 ,\n        -1.8808656 ],\n       ...,\n       [ 7.9200635 , -1.6884208 , -2.2749364 , -1.7718617 , -1.1399211 ,\n        -1.8092116 ],\n       [ 7.746097  , -2.049114  , -2.20051   , -1.6845186 , -0.84045184,\n        -1.6721164 ],\n       [ 7.880602  , -1.8670471 , -2.1236322 , -1.6987044 , -1.1565515 ,\n        -1.7241452 ]], dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"true_vals","metadata":{"execution":{"iopub.status.busy":"2022-01-05T20:37:02.387482Z","iopub.execute_input":"2022-01-05T20:37:02.387736Z","iopub.status.idle":"2022-01-05T20:37:02.394364Z","shell.execute_reply.started":"2022-01-05T20:37:02.387709Z","shell.execute_reply":"2022-01-05T20:37:02.393707Z"},"trusted":true},"execution_count":59,"outputs":[{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"array([0, 4, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 5, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 5,\n       4, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 5, 0, 0, 0, 0, 1, 0,\n       0, 0, 1, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 1, 0, 0, 1, 0, 0, 2, 0, 4,\n       0, 2, 0, 0, 0, 5, 0, 0, 3, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0,\n       0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n       1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n       0, 0, 0, 0, 4, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 4, 0, 1, 0, 0, 0,\n       0, 0, 0, 1, 0, 0, 1, 0, 0, 2, 0, 1, 2, 0, 2, 0, 0, 0, 1, 0, 0, 0,\n       5, 0, 0])"},"metadata":{}}]},{"cell_type":"code","source":"accuracy_per_class(predictions, true_vals)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T20:44:47.408490Z","iopub.execute_input":"2022-01-05T20:44:47.409052Z","iopub.status.idle":"2022-01-05T20:44:47.416072Z","shell.execute_reply.started":"2022-01-05T20:44:47.408995Z","shell.execute_reply":"2022-01-05T20:44:47.415133Z"},"trusted":true},"execution_count":68,"outputs":[{"name":"stdout","text":"class:happy\naccuracy:164/171\n\nclass:not-relevant\naccuracy:21/32\n\nclass:angry\naccuracy:6/9\n\nclass:disgust\naccuracy:0/1\n\nclass:sad\naccuracy:2/5\n\nclass:surprise\naccuracy:2/5\n\n","output_type":"stream"}]}]}